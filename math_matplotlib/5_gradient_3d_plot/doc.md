
# ğŸ“˜ BÃ i 5: HÃ m Hai Biáº¿n, Gradient, vÃ  Cá»±c Trá»‹

## 1ï¸âƒ£ HÃ m hai biáº¿n

Má»™t hÃ m hai biáº¿n lÃ  Ã¡nh xáº¡:

$$
f : \mathbb{R}^2 \to \mathbb{R}, \quad f(x, y) = z
$$

VÃ­ dá»¥:

$$
f(x, y) = x^2 + y^2
$$

GiÃ¡ trá»‹ cá»§a hÃ m phá»¥ thuá»™c Ä‘á»“ng thá»i vÃ o hai biáº¿n Ä‘áº§u vÃ o.

---

## 2ï¸âƒ£ Äáº¡o hÃ m riÃªng

Äáº¡o hÃ m riÃªng Ä‘o tá»‘c Ä‘á»™ thay Ä‘á»•i cá»§a hÃ m theo tá»«ng hÆ°á»›ng $x$ hoáº·c $y$.

$$
\frac{\partial f}{\partial x} = \lim_{h \to 0} \frac{f(x + h, y) - f(x, y)}{h}
$$

$$
\frac{\partial f}{\partial y} = \lim_{h \to 0} \frac{f(x, y + h) - f(x, y)}{h}
$$

TÃ­nh gáº§n Ä‘Ãºng:

$$
f_x(x, y) â‰ˆ \frac {f(x + h, y) - f(x - h, y)}{2h}
$$

$$
f_y(x, y) â‰ˆ \frac {f(x, y + h) - f(x, y - h)}{2h}
$$

VÃ­ dá»¥:

$$
f(x, y) = x^2 + 3xy + y^2
$$

Ta cÃ³:

$$
\frac{\partial f}{\partial x} = 2x + 3y, \quad \frac{\partial f}{\partial y} = 3x + 2y
$$

---

## 3ï¸âƒ£ Gradient (âˆ‡f)

Gradient lÃ  vector chá»©a cÃ¡c Ä‘áº¡o hÃ m riÃªng cá»§a hÃ m:

$$
\nabla f(x, y) = \left[
\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}
\right]
$$

HÆ°á»›ng cá»§a âˆ‡f cho biáº¿t hÆ°á»›ng tÄƒng nhanh nháº¥t cá»§a hÃ m $f$.  
Äá»™ lá»›n cá»§a nÃ³ cho biáº¿t tá»‘c Ä‘á»™ tÄƒng theo hÆ°á»›ng Ä‘Ã³.

---

## 4ï¸âƒ£ Ma tráº­n Hessian

Hessian mÃ´ táº£ Ä‘á»™ cong cá»§a hÃ m:

$$
H(f) =
\begin{bmatrix}
\frac{\partial^2 f}{\partial x^2} & \frac{\partial^2 f}{\partial x \partial y} \\[6pt]
\frac{\partial^2 f}{\partial y \partial x} & \frac{\partial^2 f}{\partial y^2}
\end{bmatrix}
$$

Hessian giÃºp phÃ¢n loáº¡i Ä‘iá»ƒm cá»±c trá»‹ (min, max, yÃªn ngá»±a).

---

## 5ï¸âƒ£ PhÃ¢n loáº¡i Ä‘iá»ƒm cá»±c trá»‹

Giáº£ sá»­ Ä‘iá»ƒm tá»›i háº¡n $(x_0, y_0)$ cÃ³ $\nabla f(x_0, y_0) = 0$.  
Khi Ä‘Ã³, xÃ©t **Hessian** táº¡i Ä‘iá»ƒm Ä‘Ã³:

- Náº¿u $D = f_{xx} f_{yy} - f_{xy}^2 > 0$ vÃ  $f_{xx} > 0$ â†’ **Cá»±c tiá»ƒu**.  
- Náº¿u $D > 0$ vÃ  $f_{xx} < 0$ â†’ **Cá»±c Ä‘áº¡i**.  
- Náº¿u $D < 0$ â†’ **Äiá»ƒm yÃªn ngá»±a**.  
- Náº¿u $D = 0$ â†’ **KhÃ´ng káº¿t luáº­n Ä‘Æ°á»£c**.
---

## 6ï¸âƒ£ PhÆ°Æ¡ng phÃ¡p Gradient Descent

DÃ¹ng Ä‘á»ƒ tÃ¬m Ä‘iá»ƒm cá»±c tiá»ƒu cá»§a hÃ m.

Cáº­p nháº­t vá»‹ trÃ­ theo cÃ´ng thá»©c:

$$
(x_{n+1}, y_{n+1}) = (x_n, y_n) - \alpha \nabla f(x_n, y_n)
$$

Trong Ä‘Ã³:
- $\alpha > 0$: há»‡ sá»‘ há»c (learning rate)  
- $\nabla f$: vector gradient táº¡i Ä‘iá»ƒm hiá»‡n táº¡i

QuÃ¡ trÃ¬nh láº·p Ä‘áº¿n khi $|\nabla f| < \varepsilon$.

---

## 7ï¸âƒ£ Minh há»a Ä‘á»“ thá»‹ vÃ  vector gradient

- Äá»“ thá»‹ 3D: bá» máº·t cá»§a $f(x,y)$
- Vector gradient (âˆ‡f): mÅ©i tÃªn hÆ°á»›ng theo chiá»u tÄƒng nhanh nháº¥t.
- Trong mÃ´ phá»ng, váº½ cÃ¡c mÅ©i tÃªn ngÆ°á»£c chiá»u gradient Ä‘á»ƒ tháº¥y hÆ°á»›ng **giáº£m dáº§n**.

---

## 8ï¸âƒ£ Tá»•ng káº¿t

| ThÃ nh pháº§n | KÃ½ hiá»‡u | Ã nghÄ©a |
|-------------|----------|---------|
| HÃ m hai biáº¿n | $f(x, y)$ | Äáº§u vÃ o 2 biáº¿n, Ä‘áº§u ra 1 giÃ¡ trá»‹ |
| Äáº¡o hÃ m riÃªng | $\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}$ | Äá»™ dá»‘c theo tá»«ng trá»¥c |
| Gradient | $\nabla f = [f_x, f_y]$ | HÆ°á»›ng tÄƒng nhanh nháº¥t |
| Hessian | $H(f)$ | Ma tráº­n cong báº­c hai |
| Gradient Descent | $x_{n+1} = x_n - \alpha \nabla f$ | TÃ¬m cá»±c tiá»ƒu |